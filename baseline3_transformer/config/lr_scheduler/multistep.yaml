# @package _global_
lr_scheduler:
  scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    milestones: [2, 3, 4, 5]
    gamma: 0.1
  interval: epoch
